# -*- coding: utf-8 -*-
"""Drone_Traffic_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-xdA5ZPGMLr0z6wjQ313VoS_vIlZ5I84
"""

# Install required packages
!pip install -q ultralytics deep_sort_realtime shapely openpyxl opencv-python-headless matplotlib torch torchvision

from google.colab import drive
drive.mount('/content/drive')
# set path to your file inside Drive
video_path = "/content/drive/MyDrive/VisDrone/LIG_Square_Evening.mp4"
print("Using video:", video_path)

import os
os.makedirs("/content/models", exist_ok=True)
RIT_PATH = "/content/models/rit_aerial.pth"
MANUAL_RIT_PATH = None  # if you already uploaded RIT model to Colab, put its path here, e.g. "/content/rit_aerial.pth"

def try_download_rit():
    # Try a couple of known possible raw URLs (may fail depending on hosting)
    candidates = [
        # NOTE: these are common hosting patterns — may succeed or fail depending on availability.
        "https://github.com/Eromera/erfnet_pytorch/raw/master/trained_models/RIT_combined.pth",
        "https://raw.githubusercontent.com/Eromera/erfnet_pytorch/master/trained_models/RIT_combined.pth",
    ]
    import urllib.request, ssl
    ctx = ssl.create_default_context()
    for url in candidates:
        try:
            print("Trying to download RIT++ model from:", url)
            urllib.request.urlretrieve(url, RIT_PATH)
            print("Downloaded RIT model to", RIT_PATH)
            return True
        except Exception as e:
            print("Download failed for", url, ":", str(e))
    return False

rit_ready = False
if MANUAL_RIT_PATH and os.path.exists(MANUAL_RIT_PATH):
    print("Using manual RIT model at", MANUAL_RIT_PATH)
    RIT_PATH = MANUAL_RIT_PATH
    rit_ready = True
else:
    rit_ready = try_download_rit()

if not rit_ready:
    print("\nCould not auto-download RIT++ weights. That's fine — we'll fall back to YOLOv8-seg for segmentation.\n")
    print("If you have RIT weights, upload them now (Runtime → Upload) or set MANUAL_RIT_PATH and re-run this cell.")
else:
    print("RIT++ weights ready at:", RIT_PATH)

import cv2, json, numpy as np, os
from pathlib import Path

# Paths (output)
LANES_JSON = "lanes.json"
os.makedirs("results", exist_ok=True)

# Helper: polygon extraction from mask
def mask_to_polygons(mask, min_area=5000):
    import cv2
    contours, _ = cv2.findContours(mask.astype('uint8'), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    polys = []
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if area < min_area:
            continue
        eps = 0.01 * cv2.arcLength(cnt, True)
        approx = cv2.approxPolyDP(cnt, eps, True)
        pts = [(int(p[0][0]), int(p[0][1])) for p in approx]
        if len(pts) >= 3:
            polys.append(pts)
    return polys

# Load first frame
cap = cv2.VideoCapture(video_path)
ret, frame = cap.read()
cap.release()
if not ret:
    raise RuntimeError("Couldn't read first frame from video_path: " + str(video_path))
h, w = frame.shape[:2]
print("Video frame size:", w, "x", h)

# Try RIT++ segmentation if rit file present
if os.path.exists(RIT_PATH):
    print("Using RIT++ aerial segmentation (RIT_PATH):", RIT_PATH)
    # Minimal inference using a PyTorch model (ERFNet/other architecture): we keep code general
    import torch
    # We'll attempt to load a model expecting an input RGB 3-channel tensor and output a 1-channel road mask.
    try:
        model_data = torch.load(RIT_PATH, map_location='cpu')
        # Many repos store state_dict; attempt to handle common cases
        if isinstance(model_data, dict) and 'state_dict' in model_data:
            state = model_data['state_dict']
        else:
            state = model_data
        # NOTE: repo-specific model architecture is required. For safety, instead of attempting to rebuild their model,
        # we will try a simpler approach: if the file couldn't be used directly, fall back to YOLOv8-seg.
        print("RIT++ weights loaded, but unable to instantiate architecture generically in this notebook.")
        print("Falling back to YOLOv8 segmentation as automatic fallback.")
        use_yolo_seg = True
    except Exception as e:
        print("Error loading RIT weights:", e)
        print("Falling back to YOLOv8 segmentation.")
        use_yolo_seg = True
else:
    print("No RIT++ weights available; using YOLOv8-seg fallback for segmentation.")
    use_yolo_seg = True

# If using YOLOv8 segmentation fallback:
if use_yolo_seg:
    from ultralytics import YOLO
    print("Loading YOLOv8 segmentation model (ultralytics will auto-download if needed)...")
    seg_model = YOLO("yolov8n-seg.pt")
    # Run inference on the first frame
    print("Running segmentation on the first frame...")
    res = seg_model(frame)[0]
    if getattr(res, "masks", None) is None:
        print("No masks detected by YOLOv8-seg. Creating lanes by thresholding the 'road' color area fallback.")
        # fallback: try simple morphological detection of darker road region
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        _, mask = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY_INV)  # heuristic - may vary
        mask = cv2.medianBlur(mask, 7)
        polys = mask_to_polygons(mask, min_area=3000)
    else:
        masks = res.masks.data.cpu().numpy()  # shape: (n_masks, H, W)
        # Combine masks that are likely road/lane (we'll pick the largest masks)
        polys = []
        for i in range(masks.shape[0]):
            m = (masks[i] * 255).astype('uint8')
            m = cv2.medianBlur(m, 7)
            extracted = mask_to_polygons(m, min_area=2000)
            for p in extracted:
                polys.append(p)

# If no polygons found, create a simple 4-lane guess dividing image into 4 approach lanes
if not polys:
    print("No lane polygons found automatically. Creating 4 rough default approach lanes as fallback.")
    polys = []
    # Four approximate rectangular lanes from edges toward center (simple heuristic)
    cx, cy = w//2, h//2
    offset = int(w*0.15)
    polys.append([(0, int(h*0.2)), (cx-offset, int(h*0.4)), (cx-offset, int(h*0.6)), (0, int(h*0.8))])
    polys.append([(w, int(h*0.2)), (cx+offset, int(h*0.4)), (cx+offset, int(h*0.6)), (w, int(h*0.8))])
    polys.append([(int(w*0.2), 0), (int(w*0.4), cy-offset), (int(w*0.6), cy-offset), (int(w*0.8), 0)])
    polys.append([(int(w*0.2), h), (int(w*0.4), cy+offset), (int(w*0.6), cy+offset), (int(w*0.8), h)])

lanes_json = {"lanes": []}
for idx, poly in enumerate(polys):
    lanes_json["lanes"].append({"id": idx+1, "points": poly})

with open(LANES_JSON, "w") as f:
    json.dump(lanes_json, f, indent=2)

print("Saved lanes.json with", len(polys), "polygons ->", LANES_JSON)

import cv2, json, os, math, numpy as np, pandas as pd
from ultralytics import YOLO
from deep_sort_realtime.deepsort_tracker import DeepSort
from shapely.geometry import Point, Polygon
from collections import defaultdict, deque

# Load lanes.json
with open("lanes.json") as f:
    lanes_data = json.load(f)
lane_polygons = []
for L in lanes_data["lanes"]:
    lane_polygons.append({"id": L["id"], "points": L["points"], "poly": Polygon(L["points"])})

print("Loaded lanes:", [p["id"] for p in lane_polygons])

# Detection model
det_model = YOLO("yolov8n.pt")  # will auto-download if needed
tracker = DeepSort(max_age=30)

# Video I/O
cap = cv2.VideoCapture(video_path)
fps = cap.get(cv2.CAP_PROP_FPS) or 20.0
W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

out_dir = "results"
os.makedirs(out_dir, exist_ok=True)
fourcc = cv2.VideoWriter_fourcc(*"mp4v")
out_vid = cv2.VideoWriter(os.path.join(out_dir, "debug_output.mp4"), fourcc, fps, (W, H))

# bookkeeping
track_history = defaultdict(lambda: deque(maxlen=1000))
track_meta = {}  # store class per track
track_lane = {}  # assigned lane per track

frame_idx = 0
print("Starting detection + tracking...")
while True:
    ret, frame = cap.read()
    if not ret:
        break
    frame_idx += 1

    # Run detection
    results = det_model(frame, conf=0.35, verbose=False)[0]
    dets_for_tracker = []
    if getattr(results, "boxes", None) is not None and len(results.boxes) > 0:
        for box, conf, cls in zip(results.boxes.xyxy.tolist(), results.boxes.conf.tolist(), results.boxes.cls.tolist()):
            x1, y1, x2, y2 = [int(round(v)) for v in box]
            label = det_model.model.names[int(cls)]

            # DeepSORT expects: [[left, top, width, height], confidence, class_name]
            # Convert from [x1, y1, x2, y2] to [x, y, width, height]
            dets_for_tracker.append([
                [x1, y1, x2 - x1, y2 - y1],  # bbox as [x, y, w, h]
                float(conf),                  # confidence
                label                         # class name as string
            ])

    tracks = tracker.update_tracks(dets_for_tracker, frame=frame)

    # draw lanes first
    for lp in lane_polygons:
        pts = np.array(lp["points"], dtype=np.int32)
        cv2.polylines(frame, [pts], True, (0,200,0), 2)
        cx = int(np.mean(pts[:,0])); cy = int(np.mean(pts[:,1]))
        cv2.putText(frame, f"Lane {lp['id']}", (cx-30, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,200,0), 2)

    # process tracks
    for tr in tracks:
        if not tr.is_confirmed():
            continue
        tid = tr.track_id
        l, t, r, b = [int(round(v)) for v in tr.to_ltrb()]
        cx = int((l+r)/2); cy = int((t+b)/2)
        cls = (tr.det_class or "unknown")

        # record
        track_history[tid].append((frame_idx, cx, cy))
        track_meta[tid] = cls

        # lane assignment if not assigned
        if tid not in track_lane:
            pt = Point(cx, cy)
            for lp in lane_polygons:
                if lp["poly"].contains(pt):
                    track_lane[tid] = lp["id"]
                    break

        # draw bounding box + id
        cv2.rectangle(frame, (l,t), (r,b), (255,100,0), 2)
        cv2.putText(frame, f"{tid}:{cls[:3]}", (l, t-6), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,100,0), 2)
        if tid in track_lane:
            cv2.putText(frame, f"Lane {track_lane[tid]}", (l, b+16), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,200,200), 2)

    # write frame
    out_vid.write(frame)

    if frame_idx % 200 == 0:
        print("Processed frame:", frame_idx)

cap.release()
out_vid.release()
print("Detection+tracking done. Frames processed:", frame_idx)

# Analyze tracks -> determine direction and counts
def vector_angle_deg(v1, v2):
    v1 = np.array(v1).astype(np.float32)
    v2 = np.array(v2).astype(np.float32)
    if np.linalg.norm(v1)==0 or np.linalg.norm(v2)==0:
        return 0.0
    cosang = np.clip(np.dot(v1, v2) / (np.linalg.norm(v1)*np.linalg.norm(v2)), -1.0, 1.0)
    return float(np.degrees(np.arccos(cosang)))

rows = []
for tid, hist in track_history.items():
    if len(hist) < 4:
        continue
    start = np.array(hist[0][1:3])
    end = np.array(hist[-1][1:3])
    move = end - start

    lane_id = track_lane.get(tid, None)
    # approximate lane vector if lane assigned
    lane_vec = None
    if lane_id is not None:
        for lp in lane_polygons:
            if lp["id"] == lane_id:
                pts = np.array(lp["points"])
                cen = pts.mean(axis=0)
                far_idxs = np.argsort(np.linalg.norm(pts - cen, axis=1))
                p1 = pts[far_idxs[-1]]
                p2 = pts[far_idxs[-2]]
                lane_vec = p2 - p1
                break
    # decide direction
    if lane_vec is None:
        direction = "unknown"
    else:
        ang = vector_angle_deg(move, lane_vec)
        # small angle => straight. else cross product sign for left/right
        if ang <= 30:
            direction = "straight"
        else:
            crossz = lane_vec[0]*move[1] - lane_vec[1]*move[0]
            direction = "right_turn" if crossz < 0 else "left_turn"

    rows.append({
        "track_id": tid,
        "class": track_meta.get(tid, "unknown"),
        "lane_id": lane_id,
        "direction": direction,
        "frames_seen": len(hist)
    })

df_tracks = pd.DataFrame(rows)
if df_tracks.empty:
    print("No tracks to analyze (df empty).")
else:
    # counts per lane x direction
    counts = df_tracks.groupby(["lane_id","direction"])["track_id"].nunique().reset_index().pivot(index="lane_id", columns="direction", values="track_id").fillna(0).astype(int)
    counts = counts.reset_index().sort_values("lane_id")
    counts.to_excel(os.path.join(out_dir, "traffic_counts.xlsx"), index=False)
    df_tracks.to_csv(os.path.join(out_dir, "tracks_output.csv"), index=False)
    print("Saved results to:", out_dir)
    display(counts)

from google.colab import files
files.download("results/debug_output.mp4")          # debug visualization video
files.download("results/traffic_counts.xlsx")      # final Excel
files.download("results/tracks_output.csv")        # per-track CSV (optional)
files.download("lanes.json")                       # the auto-generated lanes
