# -*- coding: utf-8 -*-
"""Drone_Traffic_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-xdA5ZPGMLr0z6wjQ313VoS_vIlZ5I84
"""

!pip install ultralytics roboflow opencv-python-headless numpy matplotlib tqdm

from google.colab import drive
drive.mount('/content/drive')
video_path = "/content/drive/MyDrive/VisDrone/TEST1.mp4"
model_path = "/content/drive/MyDrive/VisDrone/best.pt"
road_path = "/content/drive/MyDrive/VisDrone/Lane.pt"

from ultralytics import YOLO

vehicle_model = YOLO(model_path)
print("Model loaded!")

import cv2
import numpy as np
from tqdm import tqdm

cap = cv2.VideoCapture(video_path)
fps = cap.get(cv2.CAP_PROP_FPS)
W = int(cap.get(3))
H = int(cap.get(4))
frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

out = cv2.VideoWriter("detected_output.mp4", cv2.VideoWriter_fourcc(*"mp4v"), fps, (W, H))

heatmap_points = []  # store centers of all detected vehicles

for _ in tqdm(range(frames)):
    ret, frame = cap.read()
    if not ret:
        break

    results = vehicle_model(frame, verbose=False)[0]  # YOLO detect (fast)

    if results.boxes is not None:
        xyxy = results.boxes.xyxy.cpu().numpy()
        cls  = results.boxes.cls.cpu().numpy()

        for (x1, y1, x2, y2), c in zip(xyxy, cls):
            cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)

            # Save point for heatmap
            heatmap_points.append((cx, cy))

            # Draw bounding box
            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
            label = vehicle_model.names[int(c)]
            cv2.putText(frame, label, (int(x1), int(y1) - 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)

    out.write(frame)

cap.release()
out.release()

print("detected_output.mp4 created!")

import matplotlib.pyplot as plt

heat = np.zeros((H, W), dtype=np.float32)

# Plot each detection as a point in heatmap
for (x, y) in heatmap_points:
    if 0 <= x < W and 0 <= y < H:
        heat[y, x] += 1

# Smooth the heat map
heat = cv2.GaussianBlur(heat, (75, 75), 0)

plt.figure(figsize=(12, 6))
plt.imshow(heat, cmap="hot")
plt.title("Traffic Density Heatmap")
plt.colorbar()
plt.savefig("traffic_density_heatmap.png", dpi=200)
plt.show()

# Read the first frame of video again
cap = cv2.VideoCapture(video_path)
ret, first_frame = cap.read()
cap.release()

heat_norm = cv2.normalize(heat, None, 0, 255, cv2.NORM_MINMAX)
heat_color = cv2.applyColorMap(heat_norm.astype(np.uint8), cv2.COLORMAP_JET)

overlay = cv2.addWeighted(first_frame, 0.6, heat_color, 0.4, 0)

cv2.imwrite("heatmap_overlay.png", overlay)
print("heatmap_overlay.png created!")

import cv2
import numpy as np
import matplotlib.pyplot as plt

# -----------------------------
# 1. Normalize + enhance heatmap
# -----------------------------

# Normalize heatmap to 0-255
norm = cv2.normalize(heat, None, 0, 255, cv2.NORM_MINMAX)
norm = norm.astype(np.uint8)

# Optional: boost contrast so dense areas glow more
norm = cv2.equalizeHist(norm)

# Apply a high-quality colormap
heat_color = cv2.applyColorMap(norm, cv2.COLORMAP_PLASMA)

# -----------------------------
# 2. Read first video frame
# -----------------------------
cap = cv2.VideoCapture(video_path)
ret, base_frame = cap.read()
cap.release()

if not ret:
    raise ValueError("❌ Could not read first frame from video.")

H0, W0 = base_frame.shape[:2]

# Resize heatmap to match original frame size
heat_color = cv2.resize(heat_color, (W0, H0), interpolation=cv2.INTER_LINEAR)

# -----------------------------
# 3. Create overlay (adjust alpha for best clarity)
# -----------------------------
ALPHA_FRAME = 0.55   # visibility of original frame
ALPHA_HEAT  = 0.45   # visibility of heatmap

overlay = cv2.addWeighted(base_frame, ALPHA_FRAME, heat_color, ALPHA_HEAT, 0)

# -----------------------------
# 4. Save + Display
# -----------------------------
cv2.imwrite("enhanced_heatmap_overlay.png", overlay)

plt.figure(figsize=(14, 8))
plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))
plt.title("Enhanced Traffic Heatmap Overlay")
plt.axis("off")
plt.show()

from ultralytics import YOLO

road_model = YOLO(road_path)
print("Model loaded!")

import cv2
from ultralytics import YOLO
import matplotlib.pyplot as plt

# Load your model
road_model = YOLO(road_path)

# Read the first frame (same one used for heatmap)
frame = base_frame.copy()

# Run YOLO
res = road_model(frame, verbose=False)[0]

# Get detections
xyxy = res.boxes.xyxy.cpu().numpy()
cls  = res.boxes.cls.cpu().numpy()
names = res.names  # {0: 'rondpoint', 1: 'rue'}

# Draw bounding boxes
for (x1, y1, x2, y2), c in zip(xyxy, cls):
    x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])
    label = names[int(c)]

    # draw box
    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 255), 3)

    # draw label background
    cv2.rectangle(frame, (x1, y1-30), (x1 + 150, y1), (0, 255, 255), -1)

    # draw label text
    cv2.putText(frame, label, (x1+5, y1-8),
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,0), 2)

# Show result
plt.figure(figsize=(14,8))
plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
plt.axis("off")
plt.title("Detected Roads (Bounding Boxes Only)")
plt.show()

# Save
cv2.imwrite("road_detections_only.png", frame)

LANES = {
    "North_In_Left": [ (720,5), (1120,5), (1120,300), (720,300) ],
    "North_In_Right": [ (720,300), (1120,300), (1120,550), (720,550) ],

    "South_In_Left": [ (720,550), (1120,550), (1120,1075), (720,1075) ],
    "South_In_Right":[ (720,300), (1120,300), (1120,550), (720,550) ],

    "East_In_Left":  [ (1120,350), (1910,350), (1910,650), (1120,650) ],
    "East_In_Right": [ (1120,650), (1910,650), (1910,900), (1120,900) ],

    "West_In_Left":  [ (5,350), (680,350), (680,650), (5,650) ],
    "West_In_Right": [ (5,650), (680,650), (680,900), (5,900) ],
}

import cv2
import numpy as np
import matplotlib.pyplot as plt

demo = base_frame.copy()

# draw raw lane polygons
for name, pts in LANES.items():
    pts_np = np.array(pts, dtype=np.int32)

    # Draw polygon outline
    cv2.polylines(demo, [pts_np], True, (0,255,0), 3)

    # Draw label at the first vertex
    cv2.putText(
        demo,
        name,
        tuple(pts_np[0]),
        cv2.FONT_HERSHEY_SIMPLEX,
        0.6,
        (0,255,0),
        2
    )

plt.figure(figsize=(14,10))
plt.imshow(cv2.cvtColor(demo, cv2.COLOR_BGR2RGB))
plt.axis("off")
plt.title("Lane Regions (Check Before Counting)")
plt.show()

from ultralytics import YOLO
import cv2
import pandas as pd

# -------------------------------
# Load your trained vehicle model
# -------------------------------
vehicle_model = YOLO(model_path)   # <-- your uploaded .pt file
print("Model loaded!")

# -------------------------------
# Load video
# -------------------------------
video_path = "/content/drive/MyDrive/VisDrone/TEST1.mp4"
cap = cv2.VideoCapture(video_path)
fps = cap.get(cv2.CAP_PROP_FPS)
cap.release()

print("FPS:", fps)

# -------------------------------
# Prepare storage
# -------------------------------
data_rows = []
frame_id = 0

# -------------------------------
# Start YOLO tracking
# -------------------------------
tracker = vehicle_model.track(
    source=video_path,
    persist=True,
    stream=True,
    verbose=False
)

for res in tracker:

    if res.boxes is None:
        frame_id += 1
        continue

    timestamp = frame_id / fps

    xyxy = res.boxes.xyxy.cpu().numpy()
    cls  = res.boxes.cls.cpu().numpy()
    ids  = res.boxes.id.cpu().numpy()

    for box, c, tid in zip(xyxy, cls, ids):
        x1, y1, x2, y2 = box
        vehicle_type = vehicle_model.names[int(c)]
        cx = (x1 + x2) / 2
        cy = (y1 + y2) / 2

        data_rows.append({
            "vehicle_id": int(tid),
            "vehicle_type": vehicle_type,
            "frame_no": frame_id,
            "timestamp_sec": round(timestamp, 2),
            "x_center": round(cx, 2),
            "y_center": round(cy, 2),
            "x1": round(x1, 2),
            "y1": round(y1, 2),
            "x2": round(x2, 2),
            "y2": round(y2, 2)
        })

    frame_id += 1

# -------------------------------
# Save to Excel
# -------------------------------
df = pd.DataFrame(data_rows)
df.to_excel("vehicle_detection_log.xlsx", index=False)

print("Saved → vehicle_detection_log.xlsx")

import math
from collections import defaultdict

# store all observations
data_rows = []

# per vehicle_id track center points
tracks = defaultdict(list)   # vehicle_id → list of (frame_no, timestamp, cx, cy)

frame_id = 0

tracker = vehicle_model.track(
    source=video_path,
    persist=True,
    stream=True,
    verbose=False
)

for res in tracker:

    if res.boxes is None:
        frame_id += 1
        continue

    timestamp = frame_id / fps

    xyxy = res.boxes.xyxy.cpu().numpy()
    cls_arr = res.boxes.cls.cpu().numpy()
    ids_arr = res.boxes.id.cpu().numpy()

    for box, c, tid in zip(xyxy, cls_arr, ids_arr):
        x1, y1, x2, y2 = box
        vehicle_type = vehicle_model.names[int(c)]
        cx = (x1 + x2) / 2
        cy = (y1 + y2) / 2

        # store basic row
        data_rows.append({
            "vehicle_id": int(tid),
            "vehicle_type": vehicle_type,
            "frame_no": frame_id,
            "timestamp": round(timestamp, 3),
            "cx": round(cx, 2),
            "cy": round(cy, 2),
            "x1": round(x1, 2),
            "y1": round(y1, 2),
            "x2": round(x2, 2),
            "y2": round(y2, 2),
        })

        # store trajectory point
        tracks[int(tid)].append((timestamp, cx, cy))

    frame_id += 1

vehicle_stats = []

def angle_between(p1, p2):
    dx = p2[1] - p1[1]
    dy = p1[2] - p2[2]  # inverted y-axis
    ang = math.degrees(math.atan2(dy, dx))
    return (ang + 360) % 360

for vid, points in tracks.items():
    if len(points) < 2:
        continue

    total_dist = 0
    speeds = []
    directions = []

    for i in range(1, len(points)):
        t1, x1, y1 = points[i-1]
        t2, x2, y2 = points[i]

        dt = t2 - t1
        if dt <= 0:
            continue

        dist = math.hypot(x2 - x1, y2 - y1)
        total_dist += dist

        speeds.append(dist / dt)
        directions.append(angle_between(points[i-1], points[i]))

    avg_speed = sum(speeds) / len(speeds)
    avg_dir   = sum(directions) / len(directions)

    vehicle_stats.append({
        "vehicle_id": vid,
        "frames_seen": len(points),
        "avg_speed_pixels_per_sec": round(avg_speed, 2),
        "avg_direction_deg": round(avg_dir, 1),
        "total_distance_pixels": round(total_dist, 2)
    })

df_stats = pd.DataFrame(vehicle_stats)
df_stats.to_excel("vehicle_stats.xlsx", index=False)

print("Saved → vehicle_stats.xlsx")

import json

features = []

for vid, pts in tracks.items():
    coords = [(float(x), float(y)) for (_, x, y) in pts]

    feature = {
        "type": "Feature",
        "properties": {
            "vehicle_id": vid,
        },
        "geometry": {
            "type": "LineString",
            "coordinates": coords
        }
    }
    features.append(feature)

geojson = {
    "type": "FeatureCollection",
    "features": features
}

with open("trajectories.geojson", "w") as f:
    json.dump(geojson, f)

print("Saved → trajectories.geojson")

import cv2
import matplotlib.pyplot as plt
import numpy as np

cap = cv2.VideoCapture(video_path)
ret, first_frame = cap.read()
cap.release()

vis = first_frame.copy()

# random colors for each vehicle
np.random.seed(42)
colors = {vid: tuple(np.random.randint(0,255,3).tolist()) for vid in tracks}

for vid, pts in tracks.items():
    for i in range(1, len(pts)):
        _, x1, y1 = pts[i-1]
        _, x2, y2 = pts[i]
        cv2.line(vis, (int(x1),int(y1)), (int(x2),int(y2)), colors[vid], 2)

cv2.imwrite("path_visualization.png", vis)

plt.figure(figsize=(14,10))
plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))
plt.axis("off")
plt.title("Vehicle Trajectories Visualization")
plt.show()

import cv2

video_path = "/content/drive/MyDrive/VisDrone/TEST1.mp4"
cap = cv2.VideoCapture(video_path)

cap.set(cv2.CAP_PROP_POS_FRAMES, 300)  # pick any frame number
ret, frame = cap.read()

cv2.imwrite("drone_frame.png", frame)
cap.release()

import pandas as pd

df = pd.read_excel("/content/vehicle_detection_log.xlsx")
df.to_csv("vehicle_points.csv", index=False)

